{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem 2 - rag_evaluation_prime_ministers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtfMMkbQK-2n"
      },
      "source": [
        "Introduction\n",
        "\n",
        "This notebook implements Question 2(b) of the assignment, which evaluates a Retrieval-Augmented Generation (RAG) system built on top of a custom Wikipedia index of all Prime Ministers of India. The goal is to measure how effectively a language model can answer factual political questions when supported by relevant retrieved context.\n",
        "\n",
        "We begin by rebuilding an index of Wikipedia articles corresponding to each Prime Minister. These articles are cleaned, chunked (1024 token windows, 20 token overlap), and embedded using the BAAI/bge-small-en-v1.5 encoder. The chunks are stored in a VectorStoreIndex from LlamaIndex.\n",
        "\n",
        "The LLM used for generation is llama-3.1-8b-instant, served via the Groq API for fast inference.\n",
        "The dataset used for evaluation is QA.xlsx, which contains factual question–answer pairs about Indian political history.\n",
        "\n",
        "For each question, we retrieve the top-K most similar Wikipedia chunks, generate an answer with the LLM based on the retrieved context, and compare the output to the ground-truth answer using Jaccard similarity. Finally, we report the mean Jaccard score for topK = 1 and topK = 2, along with observations on retrieval effectiveness and model behavior.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FLtqflNckNkB"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install -q groq llama-index llama-index-llms-groq llama-index-embeddings-huggingface sentence-transformers beautifulsoup4 requests tqdm pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd38Gh7SmCMz",
        "outputId": "d3b1af2c-a43a-4116-d2fd-bb60842034a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-22 10:28:15.485272: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Settings configured: Groq llama3-8b-8192 + BGE embeddings.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from llama_index.core import Settings\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "# Set your Groq API key\n",
        "os.environ[\"GROQ_API_KEY\"] = \"-redacted-\"\n",
        "\n",
        "# Making sure OpenAI key is NOT used at all (ensure code does not give)\n",
        "os.environ.pop(\"OPENAI_API_KEY\", None)\n",
        "\n",
        "# HuggingFace embedding model\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
        ")\n",
        "\n",
        "# Groq LLM\n",
        "Settings.llm = Groq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# Chunking\n",
        "Settings.chunk_size = 1024\n",
        "Settings.chunk_overlap = 20\n",
        "\n",
        "print(\"Settings configured: Groq llama3-8b-8192 + BGE embeddings.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMaaQB4omtzy",
        "outputId": "9176a51c-f4d1-40ba-9470-27f9957fd8d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://en.wikipedia.org/wiki/Jawaharlal_Nehru\n",
            "Downloading https://en.wikipedia.org/wiki/Lal_Bahadur_Shastri\n",
            "Downloading https://en.wikipedia.org/wiki/Gulzarilal_Nanda\n",
            "Downloading https://en.wikipedia.org/wiki/Indira_Gandhi\n",
            "Downloading https://en.wikipedia.org/wiki/Morarji_Desai\n",
            "Downloading https://en.wikipedia.org/wiki/Charan_Singh\n",
            "Downloading https://en.wikipedia.org/wiki/Rajiv_Gandhi\n",
            "Downloading https://en.wikipedia.org/wiki/V._P._Singh\n",
            "Downloading https://en.wikipedia.org/wiki/Chandra_Shekhar\n",
            "Downloading https://en.wikipedia.org/wiki/P._V._Narasimha_Rao\n",
            "Downloading https://en.wikipedia.org/wiki/Atal_Bihari_Vajpayee\n",
            "Downloading https://en.wikipedia.org/wiki/H._D._Deve_Gowda\n",
            "Downloading https://en.wikipedia.org/wiki/Inder_Kumar_Gujral\n",
            "Downloading https://en.wikipedia.org/wiki/Manmohan_Singh\n",
            "Downloading https://en.wikipedia.org/wiki/Narendra_Modi\n",
            "Downloaded pages: 15\n",
            "Keys: ['Jawaharlal_Nehru', 'Lal_Bahadur_Shastri', 'Gulzarilal_Nanda', 'Indira_Gandhi', 'Morarji_Desai', 'Charan_Singh', 'Rajiv_Gandhi', 'V._P._Singh', 'Chandra_Shekhar', 'P._V._Narasimha_Rao', 'Atal_Bihari_Vajpayee', 'H._D._Deve_Gowda', 'Inder_Kumar_Gujral', 'Manmohan_Singh', 'Narendra_Modi']\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "PM_NAMES = [\n",
        "    \"Jawaharlal_Nehru\",\n",
        "    \"Lal_Bahadur_Shastri\",\n",
        "    \"Gulzarilal_Nanda\",\n",
        "    \"Indira_Gandhi\",\n",
        "    \"Morarji_Desai\",\n",
        "    \"Charan_Singh\",\n",
        "    \"Rajiv_Gandhi\",\n",
        "    \"V._P._Singh\",\n",
        "    \"Chandra_Shekhar\",\n",
        "    \"P._V._Narasimha_Rao\",\n",
        "    \"Atal_Bihari_Vajpayee\",\n",
        "    \"H._D._Deve_Gowda\",\n",
        "    \"Inder_Kumar_Gujral\",\n",
        "    \"Manmohan_Singh\",\n",
        "    \"Narendra_Modi\",\n",
        "]\n",
        "\n",
        "WIKI_BASE = \"https://en.wikipedia.org/wiki/\"\n",
        "OUT_DIR = Path(\"wikipedia_pm_pages\")\n",
        "OUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": (\n",
        "        \"Mozilla/5.0 (X11; Linux x86_64) \"\n",
        "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "        \"Chrome/120.0.0.0 Safari/537.36\"\n",
        "    )\n",
        "}\n",
        "\n",
        "def download_and_extract_wiki(name):\n",
        "    url = WIKI_BASE + name\n",
        "    print(f\"Downloading {url}\")\n",
        "    r = requests.get(url, headers=HEADERS, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "    # Strip non-content elements\n",
        "    for el in soup([\"script\", \"style\", \"aside\", \"footer\", \"nav\", \"sup\", \"table\", \"style\"]):\n",
        "        el.decompose()\n",
        "\n",
        "    content = soup.find(\"div\", {\"class\": \"mw-parser-output\"})\n",
        "    if content is None:\n",
        "        return soup.get_text(separator=\"\\n\")\n",
        "\n",
        "    paras = []\n",
        "    for p in content.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5']):\n",
        "        txt = p.get_text(strip=True)\n",
        "        if txt:\n",
        "            paras.append(txt)\n",
        "    return \"\\n\\n\".join(paras)\n",
        "\n",
        "downloaded = {}\n",
        "\n",
        "for name in PM_NAMES:\n",
        "    try:\n",
        "        text = download_and_extract_wiki(name)\n",
        "        fn = OUT_DIR / f\"{name}.txt\"\n",
        "        fn.write_text(text, encoding=\"utf-8\")\n",
        "        downloaded[name] = str(fn)\n",
        "        time.sleep(1)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {name}: {e}\")\n",
        "\n",
        "print(\"Downloaded pages:\", len(downloaded))\n",
        "print(\"Keys:\", list(downloaded.keys()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt8u4dVNmz1e",
        "outputId": "982e4919-21f5-4f20-a208-0c7bab03afdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total documents: 15\n",
            "Example metadata of first doc: {'source': 'Jawaharlal_Nehru'}\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from llama_index.core import Document, VectorStoreIndex\n",
        "\n",
        "docs = []\n",
        "for name, path in downloaded.items():\n",
        "    text = Path(path).read_text(encoding=\"utf-8\")\n",
        "\n",
        "    #   API\n",
        "    docs.append(Document(text=text, metadata={\"source\": name}))\n",
        "\n",
        "print(\"Total documents:\", len(docs))\n",
        "if docs:\n",
        "    print(\"Example metadata of first doc:\", docs[0].metadata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1uxT5Uzo5jx",
        "outputId": "c64c322c-bc04-4dfe-f7d6-5658e9726cd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Index built.\n"
          ]
        }
      ],
      "source": [
        "index = VectorStoreIndex.from_documents(docs)\n",
        "print(\" Index built.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "CWPo2QLvpZS6",
        "outputId": "108c58e2-cc0c-4381-e7c4-78999eebc1d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in QA.xlsx: ['Question', 'Answer']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Who was the first Prime Minister of independen...</td>\n",
              "      <td>Jawaharlal Nehru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Which Prime Minister gave the famous slogan \"J...</td>\n",
              "      <td>Lal Bahadur Shastri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who was the first and only woman to serve as t...</td>\n",
              "      <td>Indira Gandhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who was the first Prime Minister of India not ...</td>\n",
              "      <td>Morarji Desai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which Prime Minister of India never faced the ...</td>\n",
              "      <td>Charan Singh</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question               Answer\n",
              "0  Who was the first Prime Minister of independen...     Jawaharlal Nehru\n",
              "1  Which Prime Minister gave the famous slogan \"J...  Lal Bahadur Shastri\n",
              "2  Who was the first and only woman to serve as t...        Indira Gandhi\n",
              "3  Who was the first Prime Minister of India not ...        Morarji Desai\n",
              "4  Which Prime Minister of India never faced the ...         Charan Singh"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "QA_PATH = \"QA.xlsx\"\n",
        "\n",
        "qa_df = pd.read_excel(QA_PATH)\n",
        "print(\"Columns in QA.xlsx:\", qa_df.columns.tolist())\n",
        "qa_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "fimn_-T9pcns",
        "outputId": "bcc4cf0b-04b7-499a-9af6-00fd8b42cbdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total questions: 42\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Who was the first Prime Minister of independen...</td>\n",
              "      <td>Jawaharlal Nehru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Which Prime Minister gave the famous slogan \"J...</td>\n",
              "      <td>Lal Bahadur Shastri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who was the first and only woman to serve as t...</td>\n",
              "      <td>Indira Gandhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who was the first Prime Minister of India not ...</td>\n",
              "      <td>Morarji Desai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which Prime Minister of India never faced the ...</td>\n",
              "      <td>Charan Singh</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question               Answer\n",
              "0  Who was the first Prime Minister of independen...     Jawaharlal Nehru\n",
              "1  Which Prime Minister gave the famous slogan \"J...  Lal Bahadur Shastri\n",
              "2  Who was the first and only woman to serve as t...        Indira Gandhi\n",
              "3  Who was the first Prime Minister of India not ...        Morarji Desai\n",
              "4  Which Prime Minister of India never faced the ...         Charan Singh"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "QUESTION_COL = \"Question\"\n",
        "ANSWER_COL   = \"Answer\"\n",
        "\n",
        "qa_df = qa_df[[QUESTION_COL, ANSWER_COL]].dropna().reset_index(drop=True)\n",
        "print(\"Total questions:\", len(qa_df))\n",
        "qa_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k6ShkLhGphDN"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def normalize_text(text: str):\n",
        "    \"\"\"Lowercase, strip punctuation, split into tokens.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans(\n",
        "        string.punctuation,\n",
        "        \" \" * len(string.punctuation)\n",
        "    ))\n",
        "    return text.split()\n",
        "\n",
        "def jaccard_similarity(pred: str, gold: str) -> float:\n",
        "    \"\"\"\n",
        "    Jaccard = |words(pred) ∩ words(gold)| / |words(pred) ∪ words(gold)|\n",
        "    \"\"\"\n",
        "    pred_tokens = set(normalize_text(pred))\n",
        "    gold_tokens = set(normalize_text(gold))\n",
        "\n",
        "    if len(pred_tokens) == 0 and len(gold_tokens) == 0:\n",
        "        return 1.0\n",
        "    if len(pred_tokens) == 0 or len(gold_tokens) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    inter = pred_tokens & gold_tokens\n",
        "    union = pred_tokens | gold_tokens\n",
        "    return len(inter) / len(union)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IAOmh1gApkfx"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_topk(top_k: int):\n",
        "    \"\"\"\n",
        "    For each QA pair:\n",
        "      - retrieve top_k most relevant PM pages\n",
        "      - generate answer with RAG\n",
        "      - compute Jaccard(pred, gold)\n",
        "      - record which PM pages were retrieved (metadata['source'])\n",
        "    \"\"\"\n",
        "    query_engine = index.as_query_engine(similarity_top_k=top_k)\n",
        "    retriever    = index.as_retriever(similarity_top_k=top_k)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for _, row in tqdm(qa_df.iterrows(), total=len(qa_df)):\n",
        "        question    = row[QUESTION_COL]\n",
        "        gold_answer = row[ANSWER_COL]\n",
        "\n",
        "        # Retrieval\n",
        "        retrieved_nodes = retriever.retrieve(question)\n",
        "        retrieved_sources = []\n",
        "        for node in retrieved_nodes:\n",
        "            # NodeWithScore vs Node handling\n",
        "            meta = getattr(node, \"metadata\", None)\n",
        "            if meta is None and hasattr(node, \"node\"):\n",
        "                meta = getattr(node.node, \"metadata\", {})\n",
        "            if meta is None:\n",
        "                meta = {}\n",
        "            src = meta.get(\"source\", \"UNKNOWN_SOURCE\")\n",
        "            retrieved_sources.append(src)\n",
        "\n",
        "        # Generation (RAG answer)\n",
        "        response = query_engine.query(question)\n",
        "        pred_answer = str(response)\n",
        "\n",
        "        # Jaccard similarity\n",
        "        jac = jaccard_similarity(pred_answer, gold_answer)\n",
        "\n",
        "        results.append({\n",
        "            \"top_k\": top_k,\n",
        "            \"question\": question,\n",
        "            \"gold_answer\": gold_answer,\n",
        "            \"pred_answer\": pred_answer,\n",
        "            \"jaccard\": jac,\n",
        "            \"retrieved_sources\": retrieved_sources,\n",
        "        })\n",
        "\n",
        "    mean_jac = sum(r[\"jaccard\"] for r in results) / len(results)\n",
        "    return results, mean_jac\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IJtqNMvpo8g",
        "outputId": "b170965c-c50a-4ca4-9822-069dce3e5deb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [05:48<00:00,  8.30s/it]\n",
            "100%|██████████| 42/42 [12:11<00:00, 17.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Jaccard (topK=1): 0.2047\n",
            "Mean Jaccard (topK=2): 0.2119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results_k1, mean_j_k1 = evaluate_topk(1)\n",
        "results_k2, mean_j_k2 = evaluate_topk(2)\n",
        "\n",
        "print(f\"Mean Jaccard (topK=1): {mean_j_k1:.4f}\")\n",
        "print(f\"Mean Jaccard (topK=2): {mean_j_k2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
